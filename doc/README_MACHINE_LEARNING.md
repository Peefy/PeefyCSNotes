# 机器学习

* 传统机器学习：sklearn
* 深度学习：tensorflow theano pytorch
* 强化学习：
* 迁移学习：

有监督学习、无监督学习、判别模型、生成模型

[机器学习笔记](https://github.com/Peefy/StatisticalLearningMethod.Python/tree/master/src)

**1. 监督学习与非监督学习区别**

是否有监督（supervised），就看输入数据是否有标签（label）。输入数据有标签，则为有监督学习，没标签则为无监督学习。 

半监督学习：综合利用有类标的数据和没有类标的数据，来生成合适的分类函数。利用少量标注样本和大量未标注样本进行机器学习，从概率学习角度可理解为研究如何利用训练样本的输入边缘概率P(x)和条件输出概率P(y|x)的联系设计具有良好性能的分类器。

**2. L1范数和L2范数的区别**

L0范数是指向量中非0的元素的个数。(L0范数很难优化求解,非凸函数) 

L1范数是指向量中各个元素绝对值之和/n

L2范数是指向量各元素的平方和然后求平方根 

L2范数可以防止过拟合，提升模型的泛化能力，有助于处理 condition number不好下的矩阵(数据变化很小矩阵求解后结果变化很大) （核心：L2对大数，对outlier离群点更敏感！） 

下降速度：最小化权值参数L1比L2变化的快

模型空间的限制：L1会产生稀疏 L2不会。

L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。

**3. 生成模型和判别模型区别**

监督学习分为生成模型和判别模型。 

生成模型：由数据学习联合概率分布，然后求出条件概率分布作为预测的模型。给定x产生出y的生成关系。e.g. 朴素贝叶斯、隐马尔科夫

判别模型：由数据直接学习决策函数或者条件概率分布作为预测模型。给定x应该预测什么样的输出y。e. g. K近邻算法(KNN)、感知机、决策树、逻辑斯蒂回归、最大熵、支持向量机(SVM)、提升方法、条件随机场

算法的优缺点以及相应解决方案：k-means, KNN, apriori 
算法原理：LR、KNN、k-means、apriori、ID3（C45,CART）、SVM、神经网络，协同过滤，em算法

**4. svm算法的原理、如何组织训练数据、如何调节惩罚因子、如何防止过拟合、svm的泛化能力、增量学习**

* **SVM算法的原理**-间隔最大的分离超平面 
* **如何组织训练数据**-min 2/|w| st yi(wi+b)>=1
* **如何调节惩罚因子**-拉格朗日乘子法算凸二次规划.对偶 max(a)min(w,b)L(w,b,a) 
w b  
* **如何防止过拟合**-f=sign(wx+b) 
C间隔(C>0)-间隔越大 错误分类惩罚大 间隔越小 对错误分类惩罚小 
调整C正则化特征
* **svm的泛化能力**-泛化能力强
* **增量学习**-

**5. 神经网络参数相关。比如，参数的范围？如何防止过拟合？隐藏层点的个数多了怎样少了怎样？什么情况下参数是负数？**

初始权重 -0.5-0.5 0-1 
隐藏节点个数 
传输函数 
学习速率(太大不稳定 太小太慢) 
减少隐藏节点个数 
多了过拟合 

**6. 为什么要用逻辑回归？**

逻辑回归的优点： 
1.实现简单； 
2.分类计算量小、速度快，存储资源低 
缺点： 
1、容易欠拟合，一般准确度不太高 
2、只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须线性可分；

**7. 决策树算法是按什么来进行分类的?**

ID3 信息增益 
C4.5 信息增益率 
CART 基尼系数(二叉树)

**8. 朴素贝叶斯公式：**

P(Y|X)=P(X,Y)/P(X)=(P(X|Y)*P(Y))/P(X) –通过朴素贝叶斯条件独立展开 
P(A|B)=P(B|A)*P(A)/P(B) 
对于给出的待分类项，求解在此项出现的条件下各个目标类别出现的概率，哪个最大，就认为此待分类项属于哪个类别

**9. svm中rbf核函数与高斯核函数的比较:**

在SVM的应用中，径向基函数就是指高斯核函数； 
exp(-(x-c)^2/r^2) r方差c均值 svm里面 c为xj

**10. 决策树分析：**

特征选择、生成树、剪枝 if-then规则

**11. SVM有哪些优势，（x,y,z）三个特征如何用径向基核函数抽取第四维特征**

SVM算法优点： 
* 可用于线性/非线性分类，也可以用于回归； 
* 低泛化误差； 
* 容易解释； 

缺点： 
* 对参数和核函数的选择比较敏感； 
* 原始的SVM只比较擅长处理二分类问题；

**12. 如何用Logic regression建立一个广告点击次数预测模型**

输入x 

用户特征 

人口属性如年龄、性别、收入;兴趣标签;历史点击率 

广告特征 

广告类别、广告id、广告主id、行业、素材图像特征等

上下文特征 

广告位、地域、时间、操作系统、浏览器等 

输出(h(x)) 

用户是否会点击某个广告(点击的概率是多大) 

特征处理-离散化-交叉特征-归一-onehot 

用户->从广告集合里规则抽取部分->ctr预估这部分广告

**13. 举一个适合采用层次分析法的例子**

目标->准则->方案 

构建对比较矩阵(某一准则比重)

排序计算方案权重 

买钢笔->价格外观质量->可供选择的笔

**14. 关联分析中的极大频繁项集；FP增长算法**

* 扫描数据库一遍，得到频繁项的集合F和每个频繁项的支持度。把F按支持度递降排序。 
* 构造原始FPTree 以null为根 顺序插入 
* 构建频繁项集。同一个频繁项在PF树中的所有节点的祖先路径的集合。 
比如I3在FP树中一共出现了3次，其祖先路径分别是{I2，I1：2(频度为2)}，{I2：2}和{I1：2}。这3个祖先路径的集合就是频繁项I3的条件模式基。

**15. 线性分类器与非线性分类器的区别及优劣**

线性分类器：模型是参数的线性函数，分类平面是（超）平面； 

非线性分类器：模型分界面可以是曲面或者超平面的组合。 可以解决线性不可分问题(异或问题) 
典型的线性分类器有感知机，LDA，逻辑斯特回归，SVM（线性核）； 

典型的非线性分类器有kNN，决策树，SVM（非线性核） 

**16. 如何解决过拟合问题**

early stopping(设置epoch大小即计算多少次损失函数不再下降就认为达到最优)、数据集扩增（Data augmentation 可以在原始数据上做些改动，得到更多的数据）、正则化（Regularization）包括L1、L2（L2 regularization也叫weight decay），dropout(神经网络里面每次随机删除一部分隐藏神经元)。

**17. 如何选取超参数学习速率、正则项系数、Mini-batch size**

学习速率（learning rate，η）： 

学习速率太小，则会使收敛过慢，如果学习速率太大，则会导致代价函数振荡。 

尝试：先把学习速率设置为0.01，然后观察training cost的走向，如果cost在减小，那你可以

逐步地调大学习速率，试试0.1，1.0….如果cost在增大，那就得减小学习速率，试试0.001，

0.0001….经过一番尝试之后，你可以大概确定学习速率的合适的值。 

出现early stopping的，但是我们可以不stop，而是让learning rate减半，之后让程序继续

跑。下一次validation accuracy又满足no-improvement-in-n规则时，我们同样再将

learning rate减半（此时变为原始learni rate的四分之一）…继续这个过程，直到learning

rate变为想要的结果再终止程序 

正则项系数（regularization parameter, λ） 

一开始将正则项系数λ设置为0，先确定一个比较好的learning rate。然后固定该learning rate，给λ一个值（比如1.0），然后根据validation accuracy，将λ增大或者减小10倍（增减10倍是粗调节，当你确定了λ的合适的数量级后，比如λ = 0.01,再进一步地细调节，比如调节为0.02，0.03，0.009之类。） 

Mini-batch size 

将m个样本的梯度求均值，替代online learning方法中单个样本的梯度值 

**18. L1和L2正则的区别，如何选择L1和L2正则**

* L1是模型各个参数的绝对值之和。L2是模型各个参数的平方和的开方值。
* L1会趋向于产生少量的特征，而其他的特征都是0.因为最优的参数值很大概率出现在坐标轴上，这样就会导致某一维的权重为0 ，产生稀疏权重矩阵.L2会选择更多的特征，这些特征都会接近于0。最优的参数值很小概率出现在坐标轴上，因此每一维的参数都不会是0。当最小化||w||时，就会使每一项趋近于0

**19. 随机森林的学习过程：**

随机森林是有很多随机得决策树构成，它们之间没有关联。得到RF以后，在预测时分别对每一个决策树进行判断，最后使用Bagging的思想进行结果的输出 

学习过程: 

现在有N个训练样本，每个样本的特征为M个，需要建K颗树 

1从N个训练样本中有放回的取N个样本作为一组训练集（其余未取到的样本作为预测分类，评估其误差） 

2从M个特征中取m个特征左右子集特征(m

*随机森林的自助抽样、袋外估计*

每次选n个样本，lim(1-1/n)^n=1/e=0.36

自助抽样：N总体有放回的抽取n(n

**20. 随机森林中的每一棵树是如何学习的**

决策树

**21. 随机森林学习算法中CART树的基尼指数是什么**

变量的不确定性

**22. k-mean shift的机制**

迭代   

初始K个中心点(第二次开始使用上次生成的中心点) 

map计算每个样本距离那个近 输出 中心 样本 

reduce 计算每个簇的新的中心点 满足停止条件停止 不满足输出 新中心点 

**23. 实现最小二乘法**

1/2(h(x)-y)求偏导

**24. Bagging与Boosting的区别**

Bagging(并行) 

从N样本中有放回的采样N个样本 

对这N个样本在全属性上建立分类器(CART,SVM) 

重复上面的步骤，建立m个分类器 

预测的时候使用投票的方法得到结果 

Boosting(串行) 

1. 通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据有较好的效果。 
2. 通过加法模型将弱分类器进行线性组合 

区别： 
1. 样本选择上： 
Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。 
Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。 
2. 样例权重： 
Bagging：使用均匀取样，每个样例的权重相等 
Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。 
3. 预测函数： 
Bagging：所有预测函数的权重相等。 
Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。 
4. 并行计算： 
Bagging：各个预测函数可以并行生成 
Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。

**25. 动态规划**

动态规划：待求解的问题分解为若干个子阶段(下一阶段需要上一阶段结果) 
初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态 

* 问题的阶段
* 每个阶段的状态 
* 从前一个阶段转化到后一个阶段之间的递推关系

树结构 

```java
class TreeNode{ 
    int value; 
    TreeNode left; 
    TreeNode right; 
} 
```

链表结构：每个节点Node都有一个值val和指向下个节点的链接next 

```java
class Node { 
    int val; 
    Node next; 
    Node(int x) { 
        val = x; 
        next = null; 
    } 
}
```

**26. SVM原理-SVM核技巧原理，如何选择核函数**

泛化误差界的公式为： 

R(w)≤Remp(w)+Ф(n/h) 

公式中R(w)就是真实风险，Remp(w)就是经验风险(分类器在给定样本上的误差)，Ф(n/h)就是置信风险(多大程度上可以信任分类器在未知数据上分类的结果)。 

统计学习的目标从经验风险最小化变为了寻求经验风险与置信风险的和最小，即结构风险最小。

SVM正是这样一种努力最小化结构风险的算法。 

SVM算法要求的样本数是相对比较少的(小样本，并不是说样本的绝对数量少) 

非线性，是指SVM擅长应付样本数据线性不可分的情况，主要通过松弛变量（也有人叫惩罚变量）和核函数技术来实现

硬间隔支持向量机(线性分类器) 

软间隔支持向量机(线性分类器) 

非线性支持向量机(核技巧与软间隔最大化) 

线性可分：线性核函数 

线性不可分：选择非线性核函数：多项式核函数、高斯核函数、拉普拉斯核函数、sigmoid核函数

**27. PageRank原理**

PageRank两个基本假设： 
* 数量假设：入链数量越多，那么这个页面越重要。 
* 质量假设：越是质量高的页面指向页面A，则页面A越重要。

利用以上两个假设，PageRank算法刚开始赋予每个网页相同的重要性得分，通过迭代递归计算来更新每个页面节点的PageRank得分，直到得分稳定为止。 
步骤如下： 

* 在初始阶段：网页通过链接关系构建起Web图，每个页面设置相同的PageRank值，通过若干轮的计算，会得到每个页面所获得的最终PageRank值。随着每一轮的计算进行，网页当前的PageRank值会不断得到更新。 
* 在一轮中更新页面PageRank得分的计算方法：在一轮更新页面PageRank得分的计算中，每个页面将其当前的PageRank值平均分配到本页面包含的出链上，这样每个链接即获得了相应的权值。而每个页面将所有指向本页面的入链所传入的权值求和，即可得到新的PageRank得分。当每个页面都获得了更新后的PageRank值，就完成了一轮PageRank计算。

优点： 
是一个与查询无关的静态算法，所有网页的PageRank值通过离线计算获得；有效减少在线查询时的计算量，极大降低了查询响应时间。

缺点： 
* 人们的查询具有主题特征，PageRank忽略了主题相关性，导致结果的相关性和主题性降低 
* 旧的页面等级会比新页面高。因为即使是非常好的新页面也不会有很多上游链接，除非它是某个站点的子站点。 

**28. AUC的定义和本质**

ROC曲线AUC为ROC曲线下的面积 越大分类越准 

横轴：负正类率FPR FP / (FP+TN=N) 直观解释：实际是0负中，错猜多少

纵轴：真正类率TPR TP / (TP+FN=P) 直观解释：实际是1正的中，猜对多少

auc的直观含义是任意取一个正样本和负样本，正样本得分大于负样本的概率。 

分类器能输出score： 
* 先把score排序一边扫描一边计算AUC近似的认为是一个一个矩形面积累加(阶梯状的)计算麻烦
* 统计一下所有的 M×N(M为正类样本的数目，N为负类样本的数目)个正负样本对中，有多少个组中的正样本的score大于负样本的score。当二元组中正负样本的 score相等的时候，按照0.5计算。然后除以MN。实现这个方法的复杂度为O(n^2)。n为样本数（即n=M+N） 
* 对score从大到小排序，最大score对应的sample 的rank为n，第二大score对应sample的rank为n-1

然后把所有的正类样本的rank相加，再减去正类样本的score为最小的那M个值的情况。得到的就是所有的样本中有多少对正类样本的score大于负类样本的score。然后再除以M×N。即 
AUC=((所有的正例位置相加)-(M*(M+1)/2))/(M*N) 

**29. 梯度提升树gbdt和xgboost区别**

传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。 

传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。 

xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。 

Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率） 

列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。

对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。 

xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。

**30. 预处理，特征工程**

* 标准化 
* 数据归一化规范化Normalization 
* 特征二值化Binarization 
* 类别数据编码 OneHot 编码 
* 标签二值化 
* 类别编码 
* 生成多项式特征

**31. 融合框架原理，优缺点，bagging，stacking，boosting，为什么融合能提升效果**

个人理解是按照不同的思路来组合基础模型，在保证准确度的同时也提升了模型防止过拟合的能力。针对弱学习器(泛化能力弱)效果明显，个体学习器满足：1好而不同，具有多样性2不能太坏 

Boosting(串行-减少偏差) 

Bagging(并行-减少方差) 

Stacking 

不同模型之间有差异，体现不同表达能力

**32. 2G内存里找100TB数据的中位数**

KD树，聚类，hash 

散列分治：大文件散列映射多个小文件-小文件top-合并大文件top堆排序/快排 

找出5亿个int型数的中位数： 

首先将这5亿个int型数划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，根据统计结果就可以判断中位数落到哪个区域，并知道这个区域中的第几大数刚好是中位数。然后，

第二次扫描只统计落在这个区域中的那些数就可以了。

**33. 为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好**

目的是它能够让它符合我们所做的假设，使我们能够在已有理论上对其分析 

LR更适合处理稀疏数据 

逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；(哑变量) 

特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。

**34. 特征选择方法有哪些**

* 相关系数法 使用相关系数法，先要计算各个特征对目标值的相关系 
* 构建单个特征的模型，通过模型的准确性为特征排序，借此来选择特征 
* 通过L1正则项来选择特征：L1正则方法具有稀疏解的特性，因此天然具备特征选择的特性 
(分别使用L1和L2拟合，如果两个特征在L2中系数相接近，在L1中一个系数为0一个不为0，那么其实这两个特征都应该保留，原因是L1对于强相关特征只会保留一个) 
* 训练能够对特征打分的预选模型：RandomForest和LogisticRegression/GBDT等都能对模型的特征打分，通过打分获得相关性后再训练最终模型；
* 通过特征组合后再来选择特征：如对用户id和用户特征最组合来获得较大的特征集再来选择特征，这种做法在推荐系统和广告系统中比较常见
* 通过深度学习来进行特征选择
* 传统用前进或者后退法的逐步回归来筛选特征或者对特征重要性排序，对于特征数量不多的情况还是适用的
* 方差选择法计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征
* 卡方检验 经典的卡方检验是检验定性自变量对定性因变量的相关性
* 互信息法 互信息法经典的互信息也是评价定性自变量对定性因变量的相关性的
* 线性判别分析法（LDA）
* 主成分分析法（PCA）

**35. AdaBoost, GBLT, XGBoost, LightGBM**

**36. 信息熵和基尼指数的关系**

信息熵在x = 1处一阶泰勒展开就是基尼指数

**37. 如何克服过拟合，欠拟合**

L0，L1，L2正则化(如果能推导绝对是加分项，一般人最多能画个等高线，L0是NP问题)

**38. 特征比数据量还大时，选择什么样的分类器**

线性分类器，因为维度高的时候，数据一般在维度空间里面会比较稀疏，很有可能线性可分

**39. 对于维度很高的特征，你是选择线性还是非线性分类器**

线性分类器，因为维度高的时候，数据一般在维度空间里面会比较稀疏，很有可能线性可分

**40. 对于维度极低的特征，你是选择线性还是非线性分类器**

非线性分类器，因为低维空间可能很多特征都跑到一起了，导致线性不可分

**41. 正则化**

正则化是针对过拟合而提出的，以为在求解模型最优的是一般优化最小的经验风险，现在在该经验风险上加入模型复杂度这一项（正则化项是模型参数向量的范数），并使用一个rate比率来权衡模型复杂度与以往经验风险的权重，如果模型复杂度越高，结构化的经验风险会越大，现在的目标就变为了结构经验风险的最优化，可以防止模型训练过度复杂，有效的降低过拟合的风险。
奥卡姆剃刀原理，能够很好的解释已知数据并且十分简单才是最好的模型。

**42. 过拟合**

如果一味的去提高训练数据的预测能力，所选模型的复杂度往往会很高，这种现象称为过拟合。所表现的就是模型训练时候的误差很小，但在测试的时候误差很大。

产生过拟合的原因：
* **样本数据的问题**-样本数量太少。抽样方法错误，抽出的样本数据不能有效足够代表业务逻辑或业务场景。比如样本符合正态分布，却按均分分布抽样，或者样本数据不能代表整体数据的分布，样本里的噪音数据干扰过大
* **模型问题**-模型复杂度高 、参数太多，决策树模型没有剪枝，权值学习迭代次数足够多(Overtraining),拟合了训练数据中的噪声和训练样例中没有代表性的特征.

解决方法
* **样本数据方面**-增加样本数量，对样本进行降维，添加验证数据,抽样方法要符合业务场景,清洗噪声数据.
* **模型或训练问题**-控制模型复杂度，优先选择简单的模型，或者用模型融合技术。利用先验知识，添加正则项。L1正则更加容易产生稀疏解、L2正则倾向于让参数w趋向于0. 交叉验证,不要过度训练，最优化求解时，收敛之前停止迭代。决策树模型没有剪枝,权值衰减

**43. 机器学习算法数据Feature**

* 如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM
* 如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel
* 如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况

**44. ill-condition病态问题**

训练完的模型测试样本稍作修改就会得到差别很大的结果，就是病态问题

**45. L1和L2正则的区别，如何选择L1和L2正则**

他们都是可以防止过拟合，降低模型复杂度

L1是在loss function后面加上 模型参数的1范数（也就是|xi|）

L2是在loss function后面加上 模型参数的2范数（也就是sigma(xi^2)），注意L2范数的定义是sqrt(sigma(xi^2))，在正则项上没有添加sqrt根号是为了更加容易优化

L1 会产生稀疏的特征

L2 会产生更多地特征但是都会接近于0

L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。L1在特征选择时候非常有用，而L2就只是一种规则化而已。

**46. L1范数求解**

最小角回归算法：LARS算法

**47. 为什么越小的参数说明模型越简单**

过拟合的，拟合会经过曲面的每个点，也就是说在较小的区间里面可能会有较大的曲率，这里的导数就是很大，线性模型里面的权值就是导数，所以越小的参数说明模型越简单。

**48. 为什么一些机器学习模型需要对数据进行归一化？**

归一化化就是要把你需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内。
1. 归一化后加快了梯度下降求最优解的速度。等高线变得显得圆滑，在梯度下降进行求解时能较快的收敛。如果不做归一化，梯度下降过程容易走之字，很难收敛甚至不能收敛
2. 把有量纲表达式变为无量纲表达式, 有可能提高精度。一些分类器需要计算样本之间的距离（如欧氏距离），例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖（比如这时实际情况是值域范围小的特征更重要）
3. 逻辑回归等模型先验假设数据服从正态分布。

**49. **

**50. **

**51. **

**52. **

**53. **

**54. **

**55. **

**56. **

**57. **

**58. **

**59. **

**60. **

**61. **

**62. **

**63. **

**64. **

**65. **

**66. **

**67. **

**68. **

**69. **

**70. **

**71. **

**72. **

**73. **

**74. **

**75. **

**76. **

**77. **

**78. **

**79. **

**80. **

**81. **

**82. **

**83. **

**84. **

**85. **

**86. **

**87. **

**88. **

**89. **

**90. **

**91. **

**92. **

**93. **

**94. **

**95. **

**96. **

**97. **

**98. **

**99. **

**100. **

**101. **

**102. **

**103. **

**104. **

**105. **

**106. **

**107. **

**108. **

**109. **

**110. **

**111. **

**112. **

**113. **

**114. **

**115. **

**116. **

**117. **

**118. **

**119. **

**120. **

**121. **

**122. **

**123. **

**124. **

**125. **

**126. **

**127. **

**128. **

**129. **

**130. **

**131. **

**132. **

**133. **

**134. **

**135. **

**136. **

**137. **

**138. **

**139. **

**140. **

**141. **

**142. **

**143. **

**144. **

**145. **

**146. **

**147. **

**148. **

**149. **

**150. **

**151. **

**152. **

**153. **

**154. **

**155. **

**156. **

**157. **

**158. **

**159. **

**160. **

**161. **

**162. **

**163. **

**164. **

**165. **

**166. **

**167. **

**168. **

**169. **

**170. **

**171. **

**172. **

**173. **

**174. **

**175. **

**176. **

**177. **

**178. **

**179. **

**180. **

**181. **

**182. **

**183. **

**184. **

**185. **

**186. **

**187. **

**188. **

**189. **

**190. **

**191. **

**192. **

**193. **

**194. **

**195. **

**196. **

**197. **

**198. **

**199. **


